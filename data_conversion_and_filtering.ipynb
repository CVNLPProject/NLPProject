{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d6f1d68b9b108",
   "metadata": {},
   "source": [
    "# Preprocessing of the data\n",
    "\n",
    "The dataset used is the [Yelp dataset](https://www.yelp.com/dataset/download).\n",
    "It contains ~6.9 million reviews from ~150,000 businesses.\n",
    "\n",
    "The dataset is provided in json files.\n",
    "\n",
    "We want to convert the data to csv files and filter it because we only want to look at the reviews for McDonald's restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18741a84826c25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74e9c9c7a5baa82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:55:35.901487600Z",
     "start_time": "2023-11-21T22:55:35.888969800Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80f5b9f704afb61d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:19:58.590995300Z",
     "start_time": "2023-11-16T14:19:53.065060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regex to match all names that include McDonald's\n",
    "mcRegex = re.compile(r\"\\b[mM][cC] ?[dD][oO][nN][aA][lL][dD]'?[sS]?\\b\")\n",
    "mcHashMap = {}\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('yelp_dataset/yelp_academic_dataset_business.json', 'r', encoding='utf-8') as json_file:\n",
    "    with open('csv/mcdonalds_businesses.csv', 'w', newline='') as csv_file:\n",
    "        fieldnames = [\"business_id\", \"name\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for line in json_file:\n",
    "            data = json.loads(line)\n",
    "            # check if name matches mcRegex\n",
    "            if mcRegex.search(data[\"name\"]):\n",
    "                writer.writerow({\"business_id\": data[\"business_id\"], \"name\": data[\"name\"]})\n",
    "                mcHashMap[data[\"business_id\"]] = data[\"name\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "685448f9d9db0e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:20:05.103110500Z",
     "start_time": "2023-11-16T14:20:05.038518700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n"
     ]
    }
   ],
   "source": [
    "print(len(mcHashMap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726815023a4d193b",
   "metadata": {},
   "source": [
    "We found 717 McDonald's in the dataset.\n",
    "However, looking at the data, we saw that some of the found restaurants were not actually McDonald's, like for example:\n",
    "- McDonald Park\n",
    "- McDonald Pest Control\n",
    "- Max McDonald Surfboard Repair\n",
    "\n",
    "So we decided to only match the name \"McDonald's\" exactly instead of the regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac4b80e539ac6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:35:25.640320200Z",
     "start_time": "2023-11-16T14:35:22.014995500Z"
    }
   },
   "outputs": [],
   "source": [
    "mcHashMap = {}\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('yelp_dataset/yelp_academic_dataset_business.json', 'r', encoding='utf-8') as json_file:\n",
    "    with open('csv/mcdonalds_businesses.csv', 'w', newline='') as csv_file:\n",
    "        fieldnames = [\"business_id\", \"name\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for line in json_file:\n",
    "            data = json.loads(line)\n",
    "            if data[\"name\"] == \"McDonald's\":\n",
    "                writer.writerow({\"business_id\": data[\"business_id\"], \"name\": data[\"name\"]})\n",
    "                mcHashMap[data[\"business_id\"]] = data[\"name\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9213416e7c442242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:32:52.530653900Z",
     "start_time": "2023-11-16T14:32:52.460240600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n"
     ]
    }
   ],
   "source": [
    "print(len(mcHashMap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a48f179c25c92",
   "metadata": {},
   "source": [
    "It looks like we only lost 14 Businesses by matching to \"McDonald's\" exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deb305b37f0ef209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:43:25.848873900Z",
     "start_time": "2023-11-16T14:42:09.786354500Z"
    }
   },
   "outputs": [],
   "source": [
    "mcReviews = []\n",
    "errorCount = 0\n",
    "\n",
    "with open('yelp_dataset/yelp_academic_dataset_review.json', 'r', encoding='utf-8') as json_file:\n",
    "    with open('csv/mcdonalds_reviews.csv', 'w', newline='') as csv_file:\n",
    "        fieldnames = [\"business_id\", \"stars\", \"text\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if data[\"business_id\"] in mcHashMap.keys():\n",
    "                    writer.writerow({\"business_id\": data[\"business_id\"], \"stars\": data[\"stars\"], \"text\": ''.join(data[\"text\"].splitlines())})\n",
    "                    mcReviews.append(data[\"stars\"])\n",
    "            except:\n",
    "                errorCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6de23db69e4058e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:39:26.626881400Z",
     "start_time": "2023-11-16T14:39:26.569881700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of McDonald's reviews: 18149\n",
      "Number of Errors: 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of McDonald's reviews: \" + str(len(mcReviews)))\n",
    "print(\"Number of Errors: \" + str(errorCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107e8b27b2d34f7",
   "metadata": {},
   "source": [
    "We now have a total of 18149 reviews in the csv files. 61 Reviews could not be read because of some error in the encoding, we don't know why but the number of affected reviews is small, so we don't really care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3cdc7125d59ab",
   "metadata": {},
   "source": [
    "### We now have the csv files for the McDonald's data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
